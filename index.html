<script>
const micBtn = document.getElementById('micBtn');
const askBtn = document.getElementById('askBtn');
const translateBtn = document.getElementById('translateBtn');
const userInput = document.getElementById('userInput');
const responseBox = document.getElementById('response');
const debugEl = document.getElementById('debug');

let mediaRecorder, audioChunks = [], silenceTimer;
let stream, audioContext, analyser, dataArray;

// Safari & iOS detection
const ua = navigator.userAgent || '';
const isIOS = /iPad|iPhone|iPod/.test(ua);
const isSafari = /^((?!chrome|android).)*safari/i.test(ua);

/* ---------- Push-to-talk functions ---------- */
async function startRecording() {
  debugEl.textContent = '';
  if (isIOS && isSafari && !window.MediaRecorder) {
    debugEl.textContent = 'Using iPhone Safari speech recognition fallback.';
    useSpeechRecognitionFallback();
    return;
  }

  try {
    stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    mediaRecorder = new MediaRecorder(stream);
    audioChunks = [];

    mediaRecorder.ondataavailable = e => {
      if (e.data.size > 0) audioChunks.push(e.data);
    };

    mediaRecorder.onstop = async () => {
      if (silenceTimer) clearTimeout(silenceTimer);
      if (audioContext) audioContext.close();

      const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
      if (stream) stream.getTracks().forEach(t => t.stop());
      debugEl.textContent = 'Sending audio to server...';
      await sendAudioToServer(audioBlob);
      micBtn.textContent = 'ðŸŽ¤ Speak';
      micBtn.disabled = false;
    };

    // BaÅŸlat
    mediaRecorder.start();
    micBtn.textContent = 'ðŸŽ™ï¸ Listening...';
    micBtn.disabled = true;
    debugEl.textContent = 'Recording started';

    // Sessizlik algÄ±lama
    audioContext = new AudioContext();
    analyser = audioContext.createAnalyser();
    const source = audioContext.createMediaStreamSource(stream);
    source.connect(analyser);
    analyser.fftSize = 512;
    dataArray = new Uint8Array(analyser.frequencyBinCount);

    detectSilence();

  } catch (err) {
    console.error(err);
    alert('Microphone error: ' + err.message);
    micBtn.textContent = 'ðŸŽ¤ Speak';
    micBtn.disabled = false;
  }
}

function detectSilence() {
  analyser.getByteFrequencyData(dataArray);
  const avg = dataArray.reduce((a, b) => a + b, 0) / dataArray.length;

  if (avg < 5) {
    if (!silenceTimer) {
      silenceTimer = setTimeout(() => {
        debugEl.textContent = 'Silence detected â€” stopping...';
        if (mediaRecorder && mediaRecorder.state === 'recording') {
          mediaRecorder.stop();
        }
      }, 1000); // 1 saniye sessizlik
    }
  } else {
    if (silenceTimer) {
      clearTimeout(silenceTimer);
      silenceTimer = null;
    }
  }

  if (mediaRecorder && mediaRecorder.state === 'recording') {
    requestAnimationFrame(detectSilence);
  }
}

/* ---------- SpeechRecognition fallback (iPhone Safari) ---------- */
function useSpeechRecognitionFallback() {
  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
  if (!SpeechRecognition) {
    debugEl.textContent = 'SpeechRecognition API not supported on this device.';
    return;
  }

  const recognition = new SpeechRecognition();
  recognition.continuous = false;
  recognition.interimResults = false;
  recognition.lang = 'en-US'; // dil istersen otomatik algÄ±latÄ±labilir

  recognition.onstart = () => {
    micBtn.textContent = 'ðŸŽ™ï¸ Listening...';
    micBtn.disabled = true;
    debugEl.textContent = 'Listening... (Safari SpeechRecognition)';
  };

  recognition.onresult = event => {
    const text = event.results[0][0].transcript;
    userInput.value = text;
    debugEl.textContent = 'Transcription complete';
  };

  recognition.onerror = err => {
    debugEl.textContent = 'SpeechRecognition error: ' + err.error;
  };

  recognition.onend = () => {
    micBtn.textContent = 'ðŸŽ¤ Speak';
    micBtn.disabled = false;
  };

  recognition.start();
}

/* ---------- Send to worker ---------- */
async function sendAudioToServer(audioBlob) {
  const formData = new FormData();
  formData.append('file', audioBlob, 'recording.webm');
  try {
    const res = await fetch('https://mandarinopenai.furkan285saglam.workers.dev/', {
      method: 'POST',
      body: formData
    });
    const data = await res.json();
    if (data && data.text) {
      userInput.value = data.text;
      debugEl.textContent = 'Transcription complete';
    } else {
      debugEl.textContent = 'No transcription returned';
    }
  } catch (err) {
    console.error(err);
    alert('Audio send error: ' + err.message);
  }
}

/* ---------- Event listeners ---------- */
micBtn.addEventListener('click', async () => {
  if (micBtn.textContent.includes('ðŸŽ™ï¸')) {
    // stop recording manually if needed
    if (mediaRecorder && mediaRecorder.state === 'recording') {
      mediaRecorder.stop();
      debugEl.textContent = 'Stopped manually';
    }
  } else {
    await startRecording();
  }
});

/* ---------- GPT Worker ---------- */
async function askGPTWorker(prompt, mode = 'menu') {
  try {
    const res = await fetch('https://mandarinopenai.furkan285saglam.workers.dev/', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ prompt, mode })
    });
    const data = await res.json();
    return data.reply || 'No response.';
  } catch (e) {
    console.error('askGPTWorker error', e);
    return 'Error contacting GPT worker';
  }
}

/* ---------- Ask / Translate ---------- */
askBtn.addEventListener('click', async () => {
  const text = userInput.value.trim();
  if (!text) return;
  responseBox.value = 'Thinking...';
  const reply = await askGPTWorker(text, 'menu');
  responseBox.value = reply;
});

translateBtn.addEventListener('click', async () => {
  const text = userInput.value.trim();
  if (!text) return;
  responseBox.value = 'Translating...';
  const reply = await askGPTWorker(text, 'translate');
  responseBox.value = reply;
});
</script>
