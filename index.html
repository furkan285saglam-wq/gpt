<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>AI Restaurant Assistant - Push-to-Talk</title>
<style>
body { font-family: Arial, sans-serif; background:#fafafa; padding:20px; text-align:center; }
h2 { margin-bottom:6px; }
p.sub { margin-top:0; color:#555; }
textarea { width:90%; max-width:600px; height:100px; font-size:16px; margin:10px auto; padding:10px; border-radius:8px; border:1px solid #ccc; resize:vertical; display:block; }
.button-container { display:flex; flex-wrap:wrap; justify-content:center; gap:10px; margin:10px 0; }
button { background:#0078d7; color:#fff; border:none; padding:12px 20px; border-radius:8px; font-size:16px; cursor:pointer; flex:1 1 150px; max-width:200px; transition:background .15s; }
button:hover { background:#005fa3; }
button:disabled { background:#999; cursor:not-allowed; }
@media (max-width:500px) { button { flex:1 1 100%; max-width:none; } textarea { height:120px; } }
.small { font-size:13px; color:#666; margin-top:6px; }
</style>
</head>
<body>
<h2>üçΩÔ∏è AI Restaurant Assistant</h2>
<p class="sub">Press & hold üé§ to speak ‚Äî release to send</p>
<p class="sub">Speak or type in any language ‚Äî Auto stop on silence</p>

<div class="button-container">
  <button id="micBtn">üé§ Speak</button>
</div>

<textarea id="userInput" placeholder="Ask or say something..."></textarea>

<div class="button-container">
  <button id="askBtn">Ask</button>
  <button id="translateBtn">Translate</button>
</div>

<textarea id="response" placeholder="Assistant reply..." readonly></textarea>
<p class="small" id="debug"></p>

<script>
const micBtn = document.getElementById('micBtn');
const askBtn = document.getElementById('askBtn');
const translateBtn = document.getElementById('translateBtn');
const userInput = document.getElementById('userInput');
const responseBox = document.getElementById('response');
const debugEl = document.getElementById('debug');

let mediaRecorder, audioChunks, stream;
const ua = navigator.userAgent || '';
const isIOS = /iPad|iPhone|iPod/.test(ua) && !window.MSStream;
const isSafari = /^((?!chrome|android).)*safari/i.test(ua);

/* ---------- Push-to-talk functions ---------- */
const startRecording = async () => {
  if(isIOS && isSafari){
    micBtn.disabled = true;
    micBtn.textContent = 'üé§ Not supported on iPhone Safari';
    debugEl.textContent = 'iPhone Safari blocks web SpeechRecognition. Use Android/PC.';
    return;
  }
  try {
    stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    audioChunks = [];
    mediaRecorder = new MediaRecorder(stream);
    mediaRecorder.ondataavailable = e => { if(e.data.size>0) audioChunks.push(e.data); };
    mediaRecorder.start();
    micBtn.disabled = true;
    micBtn.textContent = 'üéôÔ∏è Recording...';
    debugEl.textContent = 'Recording...';
  } catch(err){
    console.error(err);
    alert('Error accessing microphone: '+(err.message||err));
    micBtn.disabled = false;
    micBtn.textContent = 'üé§ Speak';
  }
};

const stopRecording = async () => {
  return new Promise(resolve => {
    if(!mediaRecorder) return resolve(null);
    /* ---------- Silence Detection ---------- */
    const audioContext = new AudioContext();
    const source = audioContext.createMediaStreamSource(stream);
    const analyser = audioContext.createAnalyser();
    analyser.fftSize = 512;
    source.connect(analyser);
    const dataArray = new Uint8Array(analyser.frequencyBinCount);

    let silenceStart = null;
    const checkSilence = () => {
      analyser.getByteFrequencyData(dataArray);
      const avg = dataArray.reduce((a,b)=>a+b,0)/dataArray.length;
      if(avg < 5){
        if(!silenceStart) silenceStart = Date.now();
        else if(Date.now() - silenceStart > 800){
          mediaRecorder.stop();
          audioContext.close();
          return;
        }
      } else {
        silenceStart = null;
      }
      requestAnimationFrame(checkSilence);
    };
    checkSilence();

    mediaRecorder.onstop = async () => {
      const audioBlob = new Blob(audioChunks, { type:'audio/webm' });
      if(stream) stream.getTracks().forEach(track => track.stop());
      resolve(audioBlob);

      debugEl.textContent = 'Sending audio to server...';
      const formData = new FormData();
      formData.append('file', audioBlob, 'recording.webm');

      try{
        const res = await fetch('https://mandarinopenai.furkan285saglam.workers.dev/',{
          method:'POST',
          body: formData
        });
        const data = await res.json();
        if(data && data.text){
          userInput.value = data.text;
          debugEl.textContent = 'Transcription complete';
        } else {
          debugEl.textContent = 'No transcription returned';
          alert('Speech recognition failed.');
        }
      } catch(err){
        console.error(err);
        alert('Error sending audio: '+(err.message||err));
      }
      micBtn.disabled = false;
      micBtn.textContent = 'üé§ Speak';
    };
  });
};

const sendAudioToServer = async (blob) => {
  if(!blob) return;
  const formData = new FormData();
  formData.append('file', blob, 'recording.webm');
  try{
    const res = await fetch('https://mandarinopenai.furkan285saglam.workers.dev/', {
      method:'POST',
      body: formData
    });
    const data = await res.json();
    if(data && data.text){
      userInput.value = data.text;
      debugEl.textContent = 'Transcription complete';
    } else {
      debugEl.textContent = 'No transcription returned';
      alert('Speech recognition failed.');
    }
  } catch(err){
    console.error(err);
    alert('Error sending audio: '+(err.message||err));
  }
  micBtn.disabled = false;
  micBtn.textContent = 'üé§ Speak';
};

/* ---------- Push-to-talk events ---------- */
micBtn.addEventListener('mousedown', startRecording);
micBtn.addEventListener('touchstart', startRecording);
micBtn.addEventListener('mouseup', async () => {
  const blob = await stopRecording();
  await sendAudioToServer(blob);
});
micBtn.addEventListener('touchend', async () => {
  const blob = await stopRecording();
  await sendAudioToServer(blob);
});

/* ---------- GPT Worker ---------- */
async function askGPTWorker(prompt, mode='menu'){
  try{
    const res = await fetch('https://mandarinopenai.furkan285saglam.workers.dev/',{
      method:'POST',
      headers:{ 'Content-Type':'application/json' },
      body: JSON.stringify({ prompt: prompt })
    });
    const data = await res.json();
    return data.reply || 'No response.';
  } catch(e){
    console.error('askGPTWorker error',e);
    return 'Error contacting GPT worker';
  }
}

/* ---------- Ask button ---------- */
askBtn.addEventListener('click', async ()=>{
  const text = userInput.value.trim();
  if(!text) return;
  responseBox.value='Thinking...';
  try{
    const reply = await askGPTWorker(text,'menu');
    responseBox.value = reply;
  } catch(err){
    console.error(err);
    responseBox.value = 'Error: '+(err.message||err);
  }
});

/* ---------- Translate button ---------- */
translateBtn.addEventListener('click', async ()=>{
  const text = userInput.value.trim();
  if(!text) return;
  responseBox.value='Translating...';
  try{
    const reply = await askGPTWorker(text, 'translate');
    responseBox.value = reply;
  } catch(err){
    console.error(err);
    responseBox.value='Error: '+(err.message||err);
  }
});
</script>
</body>
</html>
